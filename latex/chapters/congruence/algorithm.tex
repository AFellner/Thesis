\section*{Algorithms}
\label{sec:algorithm}
\SetKwInput{KwGlobal}{Global}
\SetKw{KwInvariant}{Invariant}
\SetKw{KwAssert}{Assert}

%\newfloat{algorithm}{t}{lop}

In this section, we will present a congruence closure algorithm that is able to produce explanations.
The algorithm is a mix of the approaches of the algorithms presented in \cite{Fontaine2004} and \cite{Nieuwenhuis2005,Nieuwenhuis2007}.
The basic structure of the algorithm is inherited from \cite{Fontaine2004}, which itself inherits its structure from the algorithm of Nelson and Oppen \cite{Nelson1980}.
The technique to store and deduce equations of non constant terms is inspired from \cite{Nieuwenhuis2005,Nieuwenhuis2007}.
Additionally the proof forest structure described below, was proposed by \cite{Nieuwenhuis2005,Nieuwenhuis2007}.

\subsection*{Preliminaries}

Our congruence closure algorithm operates on curried terms.
Curried terms use a single binary function symbol to represent general terms.
More formally let $\mathcal{F}$ be a finite set of functions with a designated binary function symbol $f \in \mathcal{F}$ and let every other function symbol in $\mathcal{F}$ be a constant.
A term w.r.t. a signature of this form is called a \emph{curried term}.

It is possible to uniquely translate a general set of terms $\mathcal{T}^{\Sigma}$ with signature $\Sigma = \langle \mathcal{F},arity \rangle$ into a set of curried terms $\mathcal{T'}^{\Sigma'}$.
$\Sigma'$ is obtained from $\Sigma$ by setting $arity$ to zero for every function symbol in $\mathcal{F}$ and introducing the designated binary function symbol $f$ to $\mathcal{F}$.
The translation of a term $t \in \mathcal{T}^{\Sigma}$ is given in terms of the function $curry$.

$$
curry(t) = \Big\{
\begin{array}{ll}
	t & \text{ if } t \text{ is a constant }\\
	f(\ldots (f(f(g,curry(t_1)),curry(t_2)))\ldots,curry(t_n)) &\text{ if } t = g(t_1,\ldots, t_n)
\end{array}
$$

The idea of currying was introduced by M. Sch\"onfinkel \cite{Schoenfinkel1924} in 1924 and independently by Haskell B. Curry \cite{Curry1958} in 1958, who also lends his name to the concept.
Currying is not restricted to terms.
The general indea is to translate functions of type $A \times B \rightarrow C$ into functions of type $A \rightarrow B \rightarrow C$.
There is a close relation between currying and lambda calculus \cite{Church1936}.
Lambda calculus uses a single binary function $\lambda$.
Its arguments can either be elements of some set or again lambda terms.
For an introduction to lambda calculus, including currying in terms of lambda calculus and its relation to functional programming, see \cite{Barendregt1997}.

The benefit of working with curried terms is an easier and cleaner congruence closure algorithm that runs in optimal time $O(n \log(n))$.

Recently so called abstract congruence closure algorithms have been proposed and shown to be more efficient than traditional approaches \cite{Bachmair2000}.
The idea of abstract congruence closure is to introduce new constants for non constant terms.
Doing so, all of equations the algorithm has to take into account are of the form $c = d$ and $c = f(a,b)$, where $a,b,c,d$ are constants.
This replaces tedious preprocessing steps, for example transformation to a graph of outdegree 2 \cite{Downey1980},that are necessary for other algorithms to achieve the optimal running time.

Our method is does not employ the idea of abstract congruence closure.
We found that using currying is enough to obtain an algorithm with optimal running time and no tedious preprocessing steps.
The reason why we did not go for abstract congruence closure is, that we do not want to have the overhead of introducing and eliminating fresh constants.
In the context of proof compression, our congruence closure algorithm will be applied to relatively small instances very often.
We could introduce the extra constants for the whole proof before processing, but would still have to remove them from explanations every time we produce a new subproof.
It would be interesting to investigate, whether our intuition in that regard is right, or if it pays off to deal with extra constants.

Comming back to the explanation producing congruence closure algorithms that inspired ours, \cite{Nieuwenhuis2005,Nieuwenhuis2007} describes an abstract one using currying.
\cite{Fontaine2004} uses a traditional algorithm without currying and extra constants.
Our algorithm is a middle ground between them.

\subsection*{Congruence structure}

We call the underlying data structure of our congruence closure algorithm a \emph{congruence structure}.
A congruence structure for set of terms $\mathcal{T}$ is a collection of the following data structures.

\begin{itemize}
	\item Representative $r: \mathcal{T} \rightarrow \mathcal{T}$
	\item Congruence class $[.]: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Left neighbors $lN: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Right neighbors $rN: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Lookup table $l: \mathcal{T} \times \mathcal{T} \rightarrow \mathcal{T}$
	\item Congruence graph $g$
	\item Queue $\mathcal{Q}$ of type $\mathcal{T} \times \mathcal{T}$
	\item Current explanations $\mathcal{M}: \mathcal{T} \times \mathcal{T} \rightarrow \mathcal{E}$
\end{itemize}

The representative is one particular term of a class of congruent terms.
It is used to identify whether two terms are already in the same congruence class and the data structures used for detecting equalities derived from the congruence axiom are kept updated only for representatives.
The congruence class structure represents a set of pairwise congruent terms.
It is used to keep track which representatives have to be updated when merging the classes of two terms.
The structures left neighbor and right neighbor for every term keep track of other terms that appear as the second argument in a compound term of the form $f(a,b)$.
The lookup table is used to keep track of all compound terms in the congruence structure and to merge compound terms, which arguments are congruent.
The congruence graph stores the derived equalities in a structured way, that allows to create explanations for a given pair of terms.
Edges are added to the graph in a lazy way and the queue keeps track of the order in which edges should be added to the graph.
We call the unique congruence structure for $\mathcal{T} = \emptyset$ the \emph{empty congruence structure}.
It is not by coincidence that many of the used data structures are described as functions.
In fact our congruence closure algorithm can and is implemented in a functional way and the data structures can be implemented immutable.

\FloatBarrier

\subsection*{Congruence closure algorithms}

In this section we present the pseudocode of our congruence closure algorithm, state and prove its properties.
Most importantly we show that it the method is sound and complete and has optimal running time $O(n \log(n))$.
Computing the congruence closure of some set of equations $E$ is done by adding all of them to an ever growing congruence structure, which initially is empty.
Most algorithm pseudocodes do not include a return statement.
In fact every algorithm implicitly returns a (modified) congruence structure or simply modifies a global variable, which is the current congruence structure.
Since this has to be done in some order, we will often assume that $E$ is given as a sequence of equations rather than a set.
Adding an equation to a congruence structure is done with the \textt{addEquation} method.
The method adds boths sides of the equation to the current set of terms $\mathcal{T}$ using the \textt{addNode} method and afterwards merges the classes of the two terms.
The \texttt{addNode} method enlarges the set of terms and searches for equalities that are due to the congruence axiom.
The updates of $\mathcal{T}$ are not outlined explicitly, but are understood to happen implicitly.
The method \texttt{merge} initializes and guides the merging of terms.
The actual merging is done by the method \textt{union} by modifying the data structures.

\input{chapters/congruence/algorithms/addequation}

\input{chapters/congruence/algorithms/addnode}

\input{chapters/congruence/algorithms/merge}

\input{chapters/congruence/algorithms/lazyinsert}

\input{chapters/congruence/algorithms/lazyupdate}

\input{chapters/congruence/algorithms/union}

\begin{invariant}[Class]

For every $s \in \mathcal{T}$ and every $t \in [r(s)]$, $r(t) = r(s)$.

\label{invar:class}
\end{invariant}

\begin{proof}

Clearly the invariant is true when intializing $[s]$ in line \ref{initclass} of \textt{addNode}.

The only other point in the code that changes $[s]$ is line \ref{changeclass} of union.
Suppose the class of $u$ is enlarged by the class of $v$ in union and suppose the invariant holds before the union for those terms.
Before the update of $[r(u)]$ the representative of every term in $[r(v)]$ is set to $r(u)$.
Therefore the invariant remains valid after the update.

\end{proof}

\begin{invariant}[Lookup]

The lookup structure $l$ is defined for a pair of terms $(s,t)$ if and only if there is a term $f(a,b) \in \mathcal{T}$ such that $r(a) = r(x)$ and $r(b) = r(y)$.
\end{invariant}

\begin{proof}

Suppose $l$ is defined for some pair of terms $(s,t)$.
The value of $l(s,t)$ was either set in lines \ref{changel1} or \ref{changel2} of union or in line \ref{initl} of \textt{addNode}.
In the latter case, $l$ is set to $f(a,b)$ for the tuple $(r(a),r(b))$ and therefore the invariant holds at this point.
For changes to $r(a)$ or $r(b)$ in union the one implication of the invariant remains valid in case $l$ is defined for the new representatives, or $l$ is set for an additional pair of terms in lines \ref{changel1} or \ref{changel2}.
In case $l$ is set to $(new\_left,r(u))$ or $(r(u),new\_right)$ in union, there is an $l$-entry $l_v$ for which the invariant held before the union.
The changes in representatives of $x$ are reflected by $new\_left$ and $new\_right$, while the representative of $v$ is changed to $r(u)$.
The new entry for $l$ therefore respects the implication of the invariant.

To show the other implication, let $f(a,b) \in \mathcal{T}$.
The term $f(a,b)$ is entered via the \textt{addEquation} and subsequently via the \textt{addNode} method.
For compound terms lines \nllabel{ldefined} and \nllabel{initl} assert that $l$ is defined for $(r(a),r(b))$.
All changes to $r(a)$ or $r(b)$ must happen in union and they are reflected by matching updates to the $l$ structure.

\end{proof}


\begin{invariant}[Neighbours]

For every $s \in \mathcal{T}$, every $t_r \in rN(r(s))$ and $t_l \in lN(r(s))$, $l$ is defined for $(r(s),r(t_r))$ and $(r(t_l),r(s))$.

\end{invariant}

\begin{proof}

We show the result for the structure $rN$.
The result about $lN$ can be obtained similarly.
Since $rN$ is initialized with the empty set in line \ref{initrN} of addNode, the invariant clearly holds initially.
To show that the invariant always holds, it has to be shown that all modifications of $r$ and $rN$ do not change the invariant.
The structure $l$ is not modified after initialization.
The structure $r$ is modified in line \ref{changerep} of union.
The structure $rN$ is modified in line \ref{modifyrN} of addNode and line \ref{modifyrN2} of union.

Line \ref{modifyrN} of addNode adds $b$ to $rN(r(a))$ and the four lines before that addition show that $l$ is defined for $(r(a),r(b))$.

Union modifies $rN$ in such a way that it adds all right neighbors of some representative $r(v)$ to $rN(r(u))$.
Lines \ref{startrN} to \ref{stoprN} make sure that $l$ is defined for all these right neighbors.

\end{proof}

A consequence of this invariant is and the fact that the statement is true after inserting, that for every term $t \in \mathcal{T}$ of the form $f(a,b)$, $l$ is defined for $(r(a),r(b))$.

\begin{proposition}[Sound- \& Completeness]

Let $\mathcal{C}$ be the congruence structure obtained by adding equations $E = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle $ to the empty congruence structure.
For every $s,t \in \mathcal{T}$: $E \models s \thickapprox t$ if and only if $r(s) = r(t)$.

\end{proposition}

\begin{proof}

\textbf{Completeness}

We show that from $E \models s \thickapprox t$ follows $r(s) = r(t)$ by induction on $n$.

Base case $n=1$: $E \models s \thickapprox t$ implies either $s = t$ or $\{u_1,v_1\} = \{s,t\}$.
In the first case $r(s) = r(t)$ is trivial. 
In the second case, the claim follows from the fact that, when $(u_1,v_1)$ is entered, union is called with arguments $s$ and $t$.
After this operation $r(s) = r(t)$.

Induction hypothesis: For every sequence of equations $E_n$ with $n$ elements and every $s,t \in \mathcal{T}_{E_n}$: $E_n \models s \thickapprox t$ then $r(s) = r(t)$.

Induction step: Let $E = \langle (u_1,v_1), \ldots, (u_{n+1},v_{n+1}) \rangle$ and $E_n = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle$.
There are two cases: $E_n \models s\thickapprox t$ and $E_n \nvDash s\thickapprox t$.
In the former case, the claim follows from the induction hypothesis, the invariant class and the fact that union always changes representatives for all elements of a class.
We still have to show the claim in the latter case.
We write $E \models_n u \thickapprox v$ as an abbreviation for $E_n \nvDash u \thickapprox v$ and $E \models u \thickapprox v$.
We show the claim by induction on the structure of the terms $s$ and $t$.

Base case: $s$ or $t$ is a constant and therefore the transitivity reasoning was used to derive $E \models_n s \thickapprox t$.
In other words, there are $l$ terms $t_1,\ldots,t_l$ such that $s = t_1$, $t = t_l$ and for all $i = 1,\ldots,l-1: E \models_n t_i \thickapprox t_{i+1}$.
We prove by yet another induction on $l$ that $r(t_1) = r(t_l)$.
Base case $l = 2$. It has to be the case (up to swapping $u_{n+1}$ with $v_{n+1}$), that $E_n \models s \thickapprox u_{n+1}$ and $E_n \models t \thickapprox v_{n+1}$, and the outmost induction hypothesis implies $r(s) = r(u_{n+1})$ and $r(t) = r(v_{n+1})$.
Therefore it follows from Invariant Class, that after the call to union for $(u_{n+1},v_{n+1})$ it is the case that $r(t_1) = r(t_2)$.
Suppose that the claim holds for some $l \in \mathbb{N}$.
In the induction step, going from $l$ to $l+1$, the claim follows from a simple application of the transitivity axiom, since $t_1,\ldots,t_l$ and $t_2,\ldots,t_{l+1}$ are both sequences of length $l$.

For the induction step of the term-structure induction, suppose that $s = f(a,b)$ and $t = f(c,d)$.
There are two cases such that $E \models_n s \thickapprox t$ can be derived.
Using a transitivity chain, the claim can be shown just like in the base case.
Using the congruence axiom, it has to be the case that $E \models_n a \thickapprox c$ and $E \models_n b \thickapprox d$ (in fact one of those can also be the case without the $n$ index).
The terms $a,b,c,d$ are of lower structure than $s$ and $t$.
Therefore it follows from the induction hypothesis that $r(a) = r(c)$ and $r(b) = r(d)$.
The Invariants Neighbour and Lookup imply that either $r(s) = r(t)$ or $(s,t)$ is added to $d$ in line \ref{deduceEq1} or line line \ref{deduceEq2} of union.
Subsequently union is called for $s$ and $t$, after which $r(s) = r(t)$ holds.

\textbf{Soundness}

For $s = t$ the claim follows trivially.
Therefore we show soundness in case $s \neq t$.
We show that from $r(s) = r(t)$ follows $E \models s \thickapprox t$ by induction on the number $k$ of calls to union induced by adding all equations of $E$ to the empty congruence structure for all $s$ and $t$ that are arguments of some call to union.
The original claim then follows from invariant Class, since only union modifies the $r$ structure and the fact that two terms are in the same class if and only if union was called for some elements in the respective classes.
%Notice that only union modifies $r$ after initialization.
%Therefore the proof investigates the changes made by union and the parameters it is called when adding equations to a congruence structure.

Base case $k = 1$: $r(s) = r(t)$ implies $\{u_1,v_1\} = \{s,t\}$ and $E \models s \thickapprox t$ is trivial.
%Lines \ref{deduceEq1} and \ref{deduceEq2} do not induce any further unions, because no compound terms, that $s$ or $t$ could be a subterm of, are yet inserted in the congruence structure.

%Induction hypothesis: For every sequence of equations $E_n$ with $n$ elements and every $s,t \in \mathcal{T}_{E_n}$: $r(s) = r(t)$ after adding all $n$ equations to the empty congruence structure then $E_n \models s \thickapprox t$.

Induction hypothesis: For every $l < k$, if a set of equations $F$ induces $l$ calls to union, then from $r(s) = r(t)$ follows $F \models s \thickapprox t$ for all terms $s,t$ that are arguments of some call to union.

Induction step: Suppose $E = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle$ induces $k$ calls to union with arguments $(h_1,g_1),\ldots,(h_k,g_k)$.
The subsequence $E_n = \langle (u_1,v_1), \ldots, (u_{n-1},v_{n-1}) \rangle$ induced the first $l$ calls to union for some $n-1 \leq l < k$.
In other words, adding $(u_n,v_n)$ to the congruence structure induces the calls to union with arguments $(h_{k-l},g_{k-l}),\ldots,(h_k,g_k)$.
Union induces additional union calls in such a way that the arguments of the additional call are on parent terms of the respective original arguments.
Clearly for the first call to union with arguments $(h_{k-l},g_{k-l})$ it is the case that $E \models h_{k-l} \thickapprox g_{k-l}$, because it is an input equation.
The induction hypothesis, Invariants Lookup and Neighbour and lines \ref{startlN} to \ref{stoprN} of union ensure that all pairs $(h_m,g_m)$ are $E$ congruent for all $m = k-l+1,\ldots,k$.

%
%We show the induction step by another induction on $k-l$, i.e. the number of unions induced by adding $(u_n,v_n)$ to the congruence structure.
%Base case $k-l = 1$: Union is called for $(u_n,v_n)$ and the induces no further calls union.
%After the one call to union $r(u_n) = r(v_n)$ and clearly $E \models u_n \thickapprox v_n$.
%The fact that lines \ref{deduceEq1} and \ref{deduceEq2} of union do not induce any further calls to the method, together with the induction hypothesis and the invariants Lookup and Neighbour, imply that $E \models_n s \thickapprox t$ if and only if $s,t = \{u_n,v_n\}$.
%
%Induction step: Suppose adding $(u_n,v_n)$ induces $m$ calls to union with arguments $(h_{k-m},g_{k-m}),\ldots,(h_k,g_k)$.
%The last call to union has to be added 
%
%Adding the equation $(u_{n+1},v_{n+1})$ to the working congruence structure induces a sequence of $l$ calls to union with parameters $(h_1,g_1),\ldots,(h_l,g_l)$

%After initialization of $r$ only union modifies the structure.
%Adding $E$ to the empty congruence structure induces a sequence of calls to union with parameters $(u_1,v_1), \ldots , (u_n,v_n)$.
%We show by induction on $n$, that $E \models v_i \thickapprox u_i$

\end{proof}

\begin{proposition}[Runtime]

Let $E$ be a set of equations and $|E| = n$.
Computing the congruence closure with our congruence closure algorithm takes worst-case time $O(n \log(n))$.

\end{proposition}

\begin{proof}

Union's two for loops

\end{proof}

\FloatBarrier

\subsection*{Congruence graph}

To produce explanations, the input equations together with deduced equalities have to be stored in some data structure that supports the production of explanations.
We support two different data structures for this purpose.
Both structures store equations in a labeled graph.
A path in a congruence graph is a sequence of undirected, unweighted, labeled edges in the underlying graph.
The set of labels for both types of graphs is the set of extended equations $\mathcal{E}$.

\begin{invariant}[Paths]

For terms $s, t$ such that $s \neq t$ and a congruence structure with representative function $r$ holds if $r(s) = r(t)$ then there is a path in the congruence graph of the structure between $s$ and $t$

\end{invariant}

\begin{invariant}[Insert]

For every edge in a congruence structure between vertices $u,v$ with label $null$, 
there are $a,b,c,d \in \mathcal{T}$ such that $u = f(a,b)$, $v = f(c,d)$, 
there are paths in the underlying graphs between $a$ and $c$ aswell as $b$ and $d$.

\end{invariant}


The method inputEqs takes a path in the congruence structure and returns the input equations that were used to derive the equality between the first and the last node of the path.
Therefore, after the input of a sequence equations using the addEquation method, the statement $inputEqs(explain(s,t,g),g)$ returns an explanation for $s = t$.

\input{chapters/congruence/algorithms/inputeqs}

%Both structures use the same set of labels $\mathcal{L}$, which is defined inductively.
%\begin{align*}
  %\mathcal{L}_0 &= \{(e,\emptyset) \mid e \in \mathcal{T} \times \mathcal{T}\} \\
  %\mathcal{L}_i &= \{(null,l) \mid l \in 2^{\mathcal{L}_{i-1}}\} \\
  %\mathcal{L} &= \bigcup_{n\in \mathbb{N}} \mathcal{L}_n
%\end{align*}

\subsubsection*{Equation Graph}

A equation graph stores input and deduced equalities in a labeled weighted undirected graph $(V,E)$ with 
$V \subseteq \mathcal{T}$, $E \subseteq V \times \mathcal{E} \times V \times \mathbb{N}$.

\input{chapters/congruence/algorithms/insert_dij}

\input{chapters/congruence/algorithms/explain_dij}

\FloatBarrier

\subsubsection*{Proof Forest}

A proof forest is a collection of proof trees.
A proof tree is a labeled tree with vertices in $\mathcal{T}$ and edge labels in $\mathcal{E}$.

\input{chapters/congruence/algorithms/insert_pt}

See how BarceLogic ppl prove stuff,
-) tree is still tree after inserting
-) path to NCA forms explanation

\FloatBarrier

\subsection*{Proof Production}

In this section we describe how to produce proofs from explanations.
The basic idea is to traverse the path corresponding to the explanation, creating a transitivity chain and keeping track of the equalities in the chain that were derived using the congruence axiom.
For the congruence equalities there have to be an explanations for the arguments of the compound terms to be equal.
These explanations are transformed into proof recursively and resolved with the transitivity chain.
Since terms can never be equal to their subterms, the procedure will eventually terminate.

\input{chapters/congruence/algorithms/prodproof}

\FloatBarrier

\subsection*{Congruence Compressor}

In Section \ref{TODO} processing of a proof was defined.
The most important kind of proof processing for us is proof compression.
We want to make use of the short explanations found by the congruence closure algorithm described above.
To this end we replace subproofs with new proofs that have shorter conclusions.
Shorter conclusions lead to the need for less resolution steps further down the proof.

The Congruence Compressor does exactly this. It is defined upon the following processing function, specified in pseudocode.

\input{chapters/congruence/algorithms/compressor}

The compressor (Algorithm \ref{algo:compressor}) uses the method \texttt{fixNode} to maintain a correct proof.
The method modifies nodes with premises that have earlier been replaced by the compressor. 
Nodes with unchanged premises are not changed.
Let $n$ be a proof node that was derived by resolving $pr_1$ and $pr_2$ using pivot $\ell$.
It assumed that the values $pr_1$, $pr_2$ and $\ell$ are stored together with the node and can be accessed in constant time.
Note that the method returns $p_1$ in case non of the new premises contains the pivot.
We might as well choose $p_2$ to maintain obtain a correct node.

\input{chapters/congruence/algorithms/fixNode}

\FloatBarrier