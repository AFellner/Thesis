\section*{Explanation Producing Congruence Closure}
\label{sec:algorithm}

In this section, we present a congruence closure algorithm that is able to produce explanations.
The algorithm is a mix of the approaches of the algorithms presented in \cite{Fontaine2004} and \cite{Nieuwenhuis2005,Nieuwenhuis2007}.
The basic structure of the algorithm is inherited from \cite{Fontaine2004}, which itself inherits its structure from the algorithm of Nelson and Oppen \cite{Nelson1980}.
The technique to store and deduce equalities of non constant terms is inspired from \cite{Nieuwenhuis2005,Nieuwenhuis2007}.
Additionally the proof forest structure described below was proposed by \cite{Nieuwenhuis2005,Nieuwenhuis2007}.

\subsection*{Preliminaries}
\label{subsec:algorithms_preliminaries}

Our congruence closure algorithm operates on curried terms.
Curried terms use a single binary function symbol to represent general terms.
More formally let $\mathcal{F}$ be a finite set of functions with a designated binary function symbol $f \in \mathcal{F}$ and let every other function symbol in $\mathcal{F}$ be a constant.
A term w.r.t. a signature of this form is called a \emph{curried term}.

It is possible to uniquely translate a general set of terms $\mathcal{T}^{\Sigma}$ with signature $\Sigma = \langle \mathcal{F},arity \rangle$ into a set of curried terms $\mathcal{T'}^{\Sigma'}$.
$\Sigma'$ is obtained from $\Sigma$ by setting $arity$ to zero for every function symbol in $\mathcal{F}$ and introducing the designated binary function symbol $f$ to $\mathcal{F}$.
The translation of a term $t \in \mathcal{T}^{\Sigma}$ is given in terms of the function $curry$.

$$
curry(t) = \Big\{
\begin{array}{ll}
	t & \text{ if } t \text{ is a constant }\\
	f(\ldots (f(f(g,curry(t_1)),curry(t_2)))\ldots,curry(t_n)) &\text{ if } t = g(t_1,\ldots, t_n)
\end{array}
$$

The idea of currying was introduced by M. Sch\"onfinkel \cite{Schoenfinkel1924} in 1924 and independently by Haskell B. Curry \cite{Curry1958} in 1958, who also lends his name to the concept.
Currying is not restricted to terms.
The general idea is to translate functions of type $A \times B \rightarrow C$ into functions of type $A \rightarrow B \rightarrow C$.
There is a close relation between currying and lambda calculus \cite{Church1936}.
Lambda calculus uses a single binary function $\lambda$.
Its arguments can either be elements of some set or again lambda terms.
For an introduction to lambda calculus, including currying in terms of lambda calculus and its relation to functional programming, see \cite{Barendregt1997}.

The benefit of working with curried terms is an easier and cleaner congruence closure algorithm, while maintaining best known runtime for congruence closure algorithms of $O(n \log(n))$.
Cleaner algorithms are not only easier to implement, but should also improve the practical runtime.

Recently so called abstract congruence closure algorithms have been proposed and shown to be more efficient than traditional approaches \cite{Bachmair2000}.
The idea of abstract congruence closure is to introduce new constants for non constant terms.
Doing so, all equations the algorithm has to take into account are of the form $(c,d)$ and $(c, f(a,b))$, where $a,b,c,d$ are constants.
This replaces tedious preprocessing steps, for example transformation to a graph of outdegree 2 \cite{Downey1980},that are necessary for other algorithms to achieve the optimal running time.

Our method is does not employ the idea of abstract congruence closure.
We found that using currying is enough to obtain an algorithm with optimal running time and no tedious preprocessing steps.
The reason why we did not go for abstract congruence closure is, that we do not want to have the overhead of introducing and eliminating fresh constants.
In the context of proof compression, our congruence closure algorithm will be applied to relatively small instances very often.
We could introduce the extra constants for the whole proof before processing, but would still have to remove them from explanations every time we produce a new subproof.
It would be interesting to investigate, whether our intuition in that regard is right, or if it pays off to deal with extra constants.

Coming back to the explanation producing congruence closure algorithms that inspired our version, \cite{Nieuwenhuis2005,Nieuwenhuis2007} describes an version one using currying.
\cite{Fontaine2004} proposes a traditional algorithm without currying and extra constants.
By choosing to work with curried terms, but without extra constants, our algorithm is a middle ground between them.

\subsection*{Congruence structure}

We call the underlying data structure of our congruence closure algorithm a \emph{congruence structure}.
A congruence structure for set of terms $\mathcal{T}$ is a collection of the following data structures.
The set $\mathcal{E} = \mathcal{T} \times \mathcal{T} \cup \{null\}$ is the set of \emph{extended equality}.

\begin{itemize}
	\item Representative $r: \mathcal{T} \rightarrow \mathcal{T}$
	\item Congruence class $[.]: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Left neighbors $lN: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Right neighbors $rN: \mathcal{T} \rightarrow 2^\mathcal{T}$
	\item Lookup table $l: \mathcal{T} \times \mathcal{T} \rightarrow \mathcal{T}$
	\item Congruence graph $g$
	\item Queue $\mathcal{Q}$ of type $\mathcal{T} \times \mathcal{T}$
	\item Current explanations $\mathcal{M}: \mathcal{T} \times \mathcal{T} \rightarrow \mathcal{E}$
\end{itemize}

The representative is one particular term of a class of congruent terms.
It is used to identify whether two terms are already in the same congruence class and the data structures used for detecting equalities derived from the congruence axiom are kept updated only for representatives.
The congruence class structure represents a set of pairwise congruent terms.
It is used to keep track which representatives have to be updated when merging the classes of two terms.
The structures left neighbor and right neighbor for every term keep track of other terms that appear as the second argument in a compound term of the form $f(a,b)$.
The lookup table is used to keep track of all compound terms in the congruence structure and to merge classes of compound terms, which arguments are congruent.
The congruence graph stores the derived equalities in a structured way, that allows to create explanations for a given pair of terms.
Edges are added to the graph in a lazy way, meaning that they are buffered and only actually entered into the graph when demanded.
The queue $\mathcal{Q}$ keeps track of the order in which edges should be added to the graph.
The function $\mathcal{M}$ stores the existence of an explanation for a buffered edge.
The idea will be explained in detail in Section \ref{sec:congruencegraph}.
We call the unique congruence structure for $\mathcal{T} = \emptyset$ the \emph{empty congruence structure}.

It is not by coincidence that many of the used data structures are described as functions.
In fact our congruence closure algorithm can and is implemented in a functional way and the data structures can be implemented immutable.

\FloatBarrier

\subsection*{Congruence closure algorithm}
\label{sec:congruenceclosurealgorithm}
In this section we present our congruence closure algorithm.
We state and prove its properties.
Most importantly we show that the algorithm is sound and complete and has the best known asymptotic running time $O(n \log(n))$.
Computing the congruence closure of some set of equations $E$ is done by adding all of them to an ever growing congruence structure, which initially is empty.
Since this has to be done in some order, we will often assume that $E$ is given as a sequence of equations rather than a set.
The pseudocode of most methods do not include a return statement.
In fact every method implicitly returns a (modified) congruence structure or simply modifies a global variable, which is the current congruence structure.
Adding an equation to a congruence structure is done with the \texttt{addEquation} method.
The method adds boths sides of the equation to the current set of terms using the \texttt{addNode} method and afterwards merges the classes of the two terms.
The \texttt{addNode} method enlarges the set of terms and searches for compatible deduced equalities.
The updates of the set of terms are not outlined explicitly, but are understood to happen implicitly.
Throughout this chapter we denote this implicit set of terms by $\mathcal{T}$.
The method \texttt{merge} initializes and guides the merging of congruence classes.
The actual merging is done by the method \texttt{union} by modifying the data structures.
The method does not only merge classes, but also searches for and returns equalities of compound terms that were caused by the merge and the compatible axiom.
The classes of the terms of these extra equalities are merged, if they are not equal yet.
The congruence classes are kept track of in a graph, maintaining important information for producing explanation and proofs.
We call such a graph Congruence Graph and explain them in a more detailed fashion in Section \ref{sec:congruencegraph}.
Edges, that reflect detected equalities, are not inserted into the graph right away, but stored in queue until the insertion is requested.
The reason for adding edges in a lazy way is to produce shorter explanations and proofs and will be explained and exemplified in Section \ref{sec:proofproduction}.

\input{chapters/congruence/algorithms/addequation}

\input{chapters/congruence/algorithms/addnode}

\input{chapters/congruence/algorithms/lazyinsert}

\input{chapters/congruence/algorithms/lazyupdate}

\input{chapters/congruence/algorithms/merge}

\input{chapters/congruence/algorithms/union}

In the following pages, we will provide some invariants that are essential for proving the properties of the algorithm.
The invariants hold when initializing the respective data structures and before and after every insertion of an equation via the \texttt{addEquation} method.

\begin{invariant}[Class]

For every $s \in \mathcal{T}$ and every $t \in [r(s)]$, $r(t) = r(s)$.

\label{invar:class}
\end{invariant}
%{\color{blue} For all invariants I might need to be more specific as to when exactly they should old.}
\begin{proof}

Clearly the invariant is true when intializing $[s]$ in line \ref{initclass} of \texttt{addNode}.

The only other point in the code that changes $[s]$ is line \ref{changeclass} of union.
Suppose the class of $u$ is enlarged by the class of $v$ in union and suppose the invariant holds before the union for those terms.
Before the update of $[r(u)]$ the representative of every term in $[r(v)]$ is set to $r(u)$.
Therefore the invariant remains valid after the update.

\end{proof}

\begin{invariant}[Lookup]

The lookup structure $l$ is defined for a pair of terms $(s,t)$ if and only if there is a term $f(a,b) \in \mathcal{T}$ such that $r(a) = r(s)$ and $r(b) = r(t)$.

\end{invariant}

\begin{proof}

Suppose $l$ is defined for some pair of terms $(s,t)$.
The value of $l(s,t)$ is set either in lines \ref{changel1} or \ref{changel2} of \texttt{union} or in line \ref{initl} of \texttt{addNode}.
In the latter case, $l$ is set to $f(a,b)$ for the tuple $(r(a),r(b))$ and therefore the invariant holds at this point.
For changes to $r(a)$ or $r(b)$ in union the one implication of the invariant remains valid in case $l$ is defined for the new representatives, or $l$ is set for an additional pair of terms in lines \ref{changel2} or \ref{changel1}.
In case $l$ is set to $(new\_left,r(u))$ or $(r(u),new\_right)$ in union, there is an $l$-entry $l_v$ for which the invariant held before the union.
The changes in representatives of $x$ are reflected by $new\_left$ and $new\_right$, while the representative of $v$ is changed to $r(u)$.
The new entry for $l$ therefore respects the implication of the invariant.

To show the other implication, let $f(a,b) \in \mathcal{T}$.
The term $f(a,b)$ is entered via the \texttt{addEquation} method and subsequently via the \texttt{addNode} method.
For compound terms lines \nllabel{ldefined} and \nllabel{initl} assert that $l$ is defined for $(r(a),r(b))$.
All changes to $r(a)$ or $r(b)$ must happen in \texttt{union} and they are reflected by matching updates to the $l$ structure.

\end{proof}


\begin{invariant}[Neighbours]

For every $s \in \mathcal{T}$, every $t_r \in rN(r(s))$ and $t_l \in lN(r(s))$, $l$ is defined for $(r(s),r(t_r))$ and $(r(t_l),r(s))$.

\end{invariant}

\begin{proof}

We show the result for the structure $rN$.
The result about $lN$ can be obtained analogously.
Since $rN$ is initialized with the empty set in line \ref{initrN} of \texttt{addNode}, the invariant clearly holds initially.
To show that the invariant always holds, it has to be shown that all modifications of $r$ and $rN$ do not change the invariant.
The structure $l$ is not modified after initialization.
The structure $r$ is modified in line \ref{changerep} of union.
The structure $rN$ is modified in line \ref{modifyrN} of addNode and line \ref{modifyrN2} of union.

Line \ref{modifyrN} of \texttt{addNode} adds $b$ to $rN(r(a))$ and the four lines before that addition show that $l$ is defined for $(r(a),r(b))$.

Union modifies $rN$ in such a way that it adds all right neighbors of some representative $r(v)$ to $rN(r(u))$.
Lines \ref{startrN} to \ref{stoprN} make sure that $l$ is defined for all these right neighbors.

\end{proof}

A consequence of this invariant is the fact that, that for every term $t \in \mathcal{T}$ of the form $f(a,b)$, $l$ is defined for $(r(a),r(b))$.

\begin{proposition}[Sound- \& Completeness]

Let $r(.)$ be the representative mapping obtained by adding equations $E = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle $ to the empty congruence structure.
For every $s,t \in \mathcal{T}$: $E \models s \thickapprox t$ if and only if $r(s) = r(t)$.

\end{proposition}

\begin{proof}

\textbf{Completeness}

We show that from $E \models s \thickapprox t$ follows $r(s) = r(t)$ by induction on $n$.

\begin{itemize}
\item \textbf{Induction Base} $n=1$: $E \models s \thickapprox t$ implies either $s = t$ or $\{u_1,v_1\} = \{s,t\}$.
In the first case $r(s) = r(t)$ is trivial. 
In the second case, the claim follows from the fact that, when $(u_1,v_1)$ is entered, union is called with arguments $s$ and $t$.
After this operation $r(s) = r(t)$.

\item \textbf{Induction Hypothesis}: For every sequence of equations $E_n$ with $n$ elements and every $s,t \in \mathcal{T}_{E_n}$: $E_n \models s \thickapprox t$ then $r(s) = r(t)$.

\item \textbf{Induction Step}: Let $E = \langle (u_1,v_1), \ldots, (u_{n+1},v_{n+1}) \rangle$ and $E_n = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle$.
There are two cases: $E_n \models s\thickapprox t$ and $E_n \nvDash s\thickapprox t$.
In the former case, the claim follows from the induction hypothesis, the invariant class and the fact that union always changes representatives for all elements of a class.
We still have to show the claim in the latter case.
We write $E \models_n u \thickapprox v$ as an abbreviation for $E_n \nvDash u \thickapprox v$ and $E \models u \thickapprox v$.
We show the claim by induction on the structure of the terms $s$ and $t$.

\begin{itemize}
\item \textbf{Induction Base} $s$ or $t$ is a constant and therefore the transitivity reasoning was used to derive $E \models_n s \thickapprox t$.
In other words, there are $l$ terms $t_1,\ldots,t_l$ such that $s = t_1$, $t = t_l$ and for all $i = 1,\ldots,l-1: E \models_n t_i \thickapprox t_{i+1}$.
We prove by yet another induction on $l$ that $r(t_1) = r(t_l)$.
\begin{itemize}
\item \textbf{Induction Base} $l = 2$. It has to be the case (up to swapping $u_{n+1}$ with $v_{n+1}$), that $E_n \models s \thickapprox u_{n+1}$ and $E_n \models t \thickapprox v_{n+1}$, and the outmost induction hypothesis implies $r(s) = r(u_{n+1})$ and $r(t) = r(v_{n+1})$.
Therefore it follows from Invariant Class, that after the call to union for $(u_{n+1},v_{n+1})$ it is the case that $r(t_1) = r(t_2)$.
Suppose that the claim holds for some $l \in \mathbb{N}$.
\item \textbf{Induction Step}: going from $l$ to $l+1$, the claim follows from a simple application of the transitivity axiom, since $t_1,\ldots,t_l$ and $t_2,\ldots,t_{l+1}$ are both sequences of length $l$.
\end{itemize}
\item \textbf{Induction Step}: suppose that $s = f(a,b)$ and $t = f(c,d)$.
There are two cases such that $E \models_n s \thickapprox t$ can be derived.
Using a transitivity chain, the claim can be shown just like in the base case.
Using the compatible axiom, it has to be the case that $E \models_n a \thickapprox c$ and $E \models_n b \thickapprox d$ (in fact one of those can also be the case without the $n$ index).
The terms $a,b,c,d$ are of lower structure than $s$ and $t$.
Therefore it follows from the induction hypothesis that $r(a) = r(c)$ and $r(b) = r(d)$.
The Invariants Neighbour and Lookup imply that either $r(s) = r(t)$ or $(s,t)$ is added to $d$ in line \ref{deduceEq1} or line line \ref{deduceEq2} of union.
Subsequently union is called for $s$ and $t$, after which $r(s) = r(t)$ holds.
\end{itemize}
\end{itemize}

\textbf{Soundness}

For $s = t$ the claim follows trivially.
Therefore we show soundness in case $s \neq t$.
We show that from $r(s) = r(t)$ follows $E \models s \thickapprox t$ by induction on the number $k$ of calls to union induced by adding all equations of $E$ to the empty congruence structure for all $s$ and $t$ that are arguments of some call to union.
The original claim then follows from invariant Class, since only union modifies the $r$ structure and the fact that two terms are in the same class if and only if union was called for some elements in the respective classes.
%Notice that only union modifies $r$ after initialization.
%Therefore the proof investigates the changes made by union and the parameters it is called when adding equations to a congruence structure.
\begin{itemize}
\item \textbf{Induction Base} $k = 1$: $r(s) = r(t)$ implies $\{u_1,v_1\} = \{s,t\}$ and $E \models s \thickapprox t$ is trivial.
%Lines \ref{deduceEq1} and \ref{deduceEq2} do not induce any further unions, because no compound terms, that $s$ or $t$ could be a subterm of, are yet inserted in the congruence structure.

%Induction hypothesis: For every sequence of equations $E_n$ with $n$ elements and every $s,t \in \mathcal{T}_{E_n}$: $r(s) = r(t)$ after adding all $n$ equations to the empty congruence structure then $E_n \models s \thickapprox t$.

\item \textbf{Induction Hypothesis}: For every $l < k$, if a set of equations $F$ induces $l$ calls to union, then from $r(s) = r(t)$ follows $F \models s \thickapprox t$ for all terms $s,t$ that are arguments of some call to union.

\item \textbf{Induction Step}: Suppose $E = \langle (u_1,v_1), \ldots, (u_n,v_n) \rangle$ induces $k$ calls to union with arguments $(h_1,g_1),\ldots,(h_k,g_k)$.
The subsequence $E_n = \langle (u_1,v_1), \ldots, (u_{n-1},v_{n-1}) \rangle$ induced the first $l$ calls to union for some $n-1 \leq l < k$.
In other words, adding $(u_n,v_n)$ to the congruence structure induces the calls to union with arguments $(h_{k-l},g_{k-l}),\ldots,(h_k,g_k)$.
The first call to union with arguments $(h_{k-l},g_{k-l})$ is either an original input equation, or a deduced equality from line \ref{addnodemerge} of \texttt{addNode}.
In both cases $E \models h_{k-l} \thickapprox g_{k-l}$, which is trivial in the former case and an application of the induction hypothesis in the latter case.
Union induces additional union calls in such a way that the arguments of the additional call are on parent terms of the respective original arguments.
Therefore, using induction on the structure of terms, the original induction hypothesis, Invariants Lookup and Neighbour and lines \ref{startlN} to \ref{stoprN} of \texttt{union}, it can be shown that for all pairs $(h_m,g_m)$ and all $m = k-l+1,\ldots,k$ it is the case that $E \models h_m \thickapprox g_m$.

%
%We show the induction step by another induction on $k-l$, i.e. the number of unions induced by adding $(u_n,v_n)$ to the congruence structure.
%Base case $k-l = 1$: Union is called for $(u_n,v_n)$ and the induces no further calls union.
%After the one call to union $r(u_n) = r(v_n)$ and clearly $E \models u_n \thickapprox v_n$.
%The fact that lines \ref{deduceEq1} and \ref{deduceEq2} of union do not induce any further calls to the method, together with the induction hypothesis and the invariants Lookup and Neighbour, imply that $E \models_n s \thickapprox t$ if and only if $s,t = \{u_n,v_n\}$.
%
%Induction step: Suppose adding $(u_n,v_n)$ induces $m$ calls to union with arguments $(h_{k-m},g_{k-m}),\ldots,(h_k,g_k)$.
%The last call to union has to be added 
%
%Adding the equation $(u_{n+1},v_{n+1})$ to the working congruence structure induces a sequence of $l$ calls to union with parameters $(h_1,g_1),\ldots,(h_l,g_l)$

%After initialization of $r$ only union modifies the structure.
%Adding $E$ to the empty congruence structure induces a sequence of calls to union with parameters $(u_1,v_1), \ldots , (u_n,v_n)$.
%We show by induction on $n$, that $E \models v_i \thickapprox u_i$
\end{itemize}
\end{proof}

\begin{proposition}[Runtime]
\label{prop:runtime}
Let $E$ be a set of equations such that $|\mathcal{T}_E| = n$.
Computing the congruence closure with our congruence closure algorithm takes worst-case time $O(n \log(n))$.

\end{proposition}

\begin{proof}

There are three loops in the method \texttt{union}, which are nested within the loop of \texttt{merge}.
These loops are clearly the dominating factor for runtime.

Lines \ref{reverse1} and \ref{reverse2} of \texttt{union} ensure that whenever the representative of a term is changed in line \ref{changerep}, the size of its resulting congruence class is doubled in line \ref{changeclass}.
Only the representative of terms of the smaller congruence class are changed and the size of the resulting class is at the combined size of the original ones, i.e. size of the small one plus size of the big one, which is at least double the size of the small one.
The maximum size of a congruence class is $n$.
Therefore the representative of a single term is changed maximally $\log(n)$ times overall and line \ref{changerep} of \texttt{union} is not executed more than $n \log(n)$ times.

{\color{blue} I am not yet sure how to prove, and to be honest even whether it is true, that line the right neighbor, left neighbor loops of union are not executed $n^2$ times overall.}

\end{proof}


\FloatBarrier

\subsection*{Congruence Graph}
\label{sec:congruencegraph}
The main goal of this work is to replace redundant explanations with shorter ones.
For this purpose the input equations and deduced equalities have to be stored in a data structure that supports the production of explanations.
We support two different such data structures.
Both structures store equalities in labeled graphs, which we call congruence graphs.
A node in such a graph represents a term and an edge between two nodes denotes that the represented terms are congruent w.r.t. the set of input equations.
A path in a congruence graph is a sequence of undirected, unweighted, labeled edges in the underlying graph.
The set of labels for both types of graphs is the set of extended equalities $\mathcal{E}$.
Depending on the type of congruence graph used, it is not guaranteed that after \texttt{lazy\_insert} is called with arguments $s$ and $t$, there is an edge between $s$ and $t$.
However it is guaranteed that the arguments are connected in the graph afterwards, i.e. there is a path between the nodes representing the terms.

\begin{invariant}[Paths]

For terms $s, t$ such that $s \neq t$ and a congruence structure with representative function $r$ holds $r(s) = r(t)$ if and only if there is a path in the congruence graph of the structure between $s$ and $t$

\end{invariant}

\begin{proof}

We show the claim by an induction on $|[r(s)]|$.
%We show that there is a path between $s$ and $t$ in the congruence graph induction on $|[r(s)]|$. 
The proof relies on the invariant Class, which shows the consistency between classes and representatives.

In the induction base $[r(s)] = \{s\}$, i.e. $r(s) = r(t)$ is false for every term $t \neq s$.
We have to show that there is no edge $(s,t)$ for $t \neq s$ in the congruence graph.
Edges are only added to the congruence graph via the \texttt{lazy\_insert} method which is only called in \texttt{merge}.
Clearly \texttt{merge} does not call \texttt{union} for $s$ and some term $t \neq s$, since otherwise $t \in [r(s)]$.
Therefore \texttt{merge} also does not add an edge for $s$ and some term $t \neq s$ to the congruence graph.

Let the induction hypothesis be, that for every term $s$ such that $|[r(s)]| \leq n$, for every term $t \neq s$ it is the case that $r(s) = r(t)$ if and only if there is a path between $s$ and $t$ in the congruence graph.

Suppose $[r(s)]$ is an arbitrary class with cardinality $n+1$.
Then there are two terms $u,v \in [r(s)]$ such that \texttt{union} was called for $u$ and $v$.
Before the union $|[r(u)]|$ and $|[r(v)]|$ both were strictly smaller than $n+1$.
In case they both belong to the same class before the union, the claim follows trivially by the induction hypothesis, since existing paths are not removed by adding new edges to the graph.
Suppose $s \in [r(u)]$ and $t \in [r(v)]$, then by induction hypothesis there are paths $p_1$ between $s$ and $u$ and $p_2$ between $t$ and $v$.
Right after the union of $u$ and $v$, an edge is inserted between them, so $p_1$ concatenated with $(u,v)$ and $p_2$ is a path between $s$ and $t$.
In case one of the terms did not belong to one of the classes before the union, it does not belong to the merged class after the union.
Also there was no path between the two terms before and since the only addition paths are between elements of $[r(u)]$ and $[r(v)]$, there is no path between the terms after the union.

\end{proof}

\begin{invariant}[Deduced Edges]

For every edge in a congruence structure between vertices $u,v$ with label $null$, 
there are $a,b,c,d \in \mathcal{T}$ such that $u = f(a,b)$, $v = f(c,d)$ and
there are paths in the underlying graphs between $a$ and $c$ aswell as $b$ and $d$.

\end{invariant}

\begin{proof}

Edges with label $null$ are added, when \texttt{merge} is called from \texttt{addNode}, or \texttt{union} induces an additional merge.
In both cases there are subterms with respective equal representatives.
The claim follows by using the invariant Paths.

\end{proof}

The method \texttt{explain} returns a path between its two arguments, if one exists.
Depending on the actual type of graph used, this path can be unique or not.
The method \texttt{inputEqs} for a path in the congruence graph returns the input equations that were used to derive the equality between the first and the last node of the path.
For an input equation, this is simply the equation itself.
For a deduced equality, this is the set of input equations that were used for deduction.
Combining these two methods, the statement \texttt{inputEqs(explain(s,t,g),g)} returns an explanation for $E \models s \thickapprox t$ if there is one.

\input{chapters/congruence/algorithms/inputeqs}

In the following, we describe the two types of congruence graphs we support.
They differ in the type of graph they use and how explanations are produced.

\subsubsection*{Equation Graph}

A equation graph stores input and deduced equalities in a labeled weighted undirected graph $(V,E)$ with 
$V \subseteq \mathcal{T}$, $E \subseteq V \times \mathcal{E} \times V \times \mathbb{N}$.
The weight for an edge is the number of input equalities used to derive the equality between its two nodes.
This number is one for input equalities and the size of the explanation for deduced equalities.
Edges are added to the graph, regardless whether the nodes are already connected in the graph.
Therefore there is a choice which path the explain method returns.
To produce short explanations, the shortest path w.r.t. the edge weights is returned.

Finding the shortest path between two nodes in a weighted graph is not trivial.
The single source shortest path problem (SSSP) is a classical graph problem in computer science.
The task is to find the shortest path in a graph between one designated node, the source, and all other nodes in the graph.
To the best knowledge of the authors, there is no algorithm to find the shortest path between two nodes which has better asymptotic runtime than one to solve SSSP.
There is a whole variety of algorithms that solve SSSP.
Classical algorithms for SSSP are those of Dijkstra \cite{Dijkstra1959} and Bellman-Ford \cite{Ford1956,Bellman1956}.
The algorithms work on different kinds of graphs.
Our setting is an undirected graph with positive integer weights.
We chose to use Dijkstra's algorithm, even though the algorithm does not have optimal asymptotic runtime.
It's worst-case runtime is $O(n \log(n))$ \cite{Cormen1989}, if the priority queue is implemented as a Fibonacci Heap, which is the case in our implementation.
\cite{Thorup1999} reports of an linear time algorithm for the undirected single source shortest path with positive integer weights problem.
However, the algorithm has a big overhead and needs several precomputations.
\cite{Cherkassky1996} is an extensive study of several shortest path algorithms which shows that Dijkstra's algorithm performs well in practice.

Dijkstra's algorithm finds shortest paths to an increasing set of nodes, until every node has been discovered.
It does so by keeping track of the the shortest paths and the distances, being the combined weights of edges on the path, of nodes to the source.
Initially, the only discovered node is the source itself and the distance to every other node is infinite.
The algorithm discovers new nodes by selecting the lowest weight outgoing edge of all nodes that have been discovered so far and updates shortest paths and distances while doing so.
It is a greedy algorithm in the sense that it always locally chooses lowest weight edges and never discards previously made decisions.

The algorithm has been slightly modified to take into account decisions that are edges for deduced equalities.
These edges represent explanations, which are a sets of input equations.
Previously included input equations do not increase the size of the global explanation when including them again.
Therefore the modified Dijkstra algorithm adds an edge with weight 0 for every input equation in the explanation of a deduced equality edge.
This is done to reduce the size of explanations.
Since previous decisions are not discarded, it is not guaranteed that the modified algorithm returns the shortest path in the final graph, including the extra edges.
Example \ref{ex:short_expl} demonstrates that the modified shortest path algorithm does not always produce the shortest explanation, but can produce shorter explanations than the unmodified version in some situations.
The shortest path algorithm's inability to return shortest explanations is not surprising, since it runs in $O(n \log(n))$ and in Section \ref{sec:sec:npcomplete} it was shown that finding the shortest explanation is NP-complete.

\begin{example}
Consider the congruence graph shown in Figure \ref{fig:short_expl}, where solid edges are input equation and the dashed edge marks an application of the congruence axiom.
The equality of $f(c_1,e)$ and $f(c_4,e)$ was deduced using the equations $(c_1,c_2),(c_2,c_3),(c_3,c_4)$, which is the shortest path in the graph between $c_1$ and $c_4$, obtained from a previous call to the shortest path algorithm.

Suppose we want to compute an explanation for $a \thickapprox b$.
Clearly the input equalities $(a,f(c_1,e))$, $(f(c_4,e),c_1)$ and the explanation for $f(c_1,e) \thickapprox f(c_4,e)$ have to be included in the explanation.
Additionally $c_1 \thickapprox b$ has to be explained.
For this equality the set $(c_1,d_1),(d_1,d_2),(d_2,b)$ is the shortest explanation in the original graph.
This sub explanation adds three new equations to the explanation for $a \thickapprox b$.
Therefore when the shortest path algorithm iterates over the edge $(f(c_1,e),f(c_4,e))$, it can add add zero weight edges $(c_1,c_2),(c_2,c_3),(c_3,c_4)$ to the graph.
By doing so the shortest explanation for $c_1 \thickapprox b$ becomes $(c_1,c_2),(c_2,c_3),(c_3,c_4),(c_4,b)$, which only adds one extra equation to the global explanation.

This method is successful in finding the shortest explanation in this example if the search begins in the node $a$.
Should the search begin in the node $b$, the edges including $d_1$, $d_2$ are added to the shortest path before the edge $(f(c_1,e),f(c_4,e))$ is touched.
Therefore the undesired long explanation would be returned.

\begin{figure}[!h]
\input{chapters/congruence/figures/dijkstra}
\caption{Short explanation example}
\label{fig:short_expl}
\end{figure}

\label{ex:short_expl}
\end{example}

\input{chapters/congruence/algorithms/insert_dij}

\input{chapters/congruence/algorithms/explain_dij}

\FloatBarrier

\subsubsection*{Proof Forest}

A proof forest is a collection of proof trees.
A proof tree is a labeled tree with nodes in $\mathcal{T}$ and edge labels in $\mathcal{E}$.
For every congruence class in the current status of a congruence structure, there is one proof tree.
Inserting an edge between nodes $s$ and $t$ of different proof trees is done by making one the child of the other.
To maintain a tree structure, all edges between the new child and the root of its tree are reversed.
To limit the number of edge revering steps, the smaller tree is always attached to the bigger one.
This results in $O(n \log(n))$ edge reversing steps, where $n$ is the number terms in the input equation set.
This bound can be shown using the same argument as in the proof of Proposition \ref{prop:runtime}.
As stated earlier, we understand a path as a sequence of undirected edges.
In case of a proof tree, a path between $s$ and $t$ of the same tree is the combined sequence of edges between the nodes and their nearest common ancestors.
The structure, up to small changes, was proposed by \cite{Nieuwenhuis2005,Nieuwenhuis2007}.
Its benefit is the quick access of explanations and good overall runtime.
Its downside is its inflexibility when it comes to producing alternative explanations.
In fact the explanation returned is always the first one to occur during edge insertion.
The authors improve the structure for the special case of flattened terms, for which no term has nesting depth greater than one.

\input{chapters/congruence/algorithms/insert_pt}

\input{chapters/congruence/algorithms/explain_pt}

\begin{example}

Consider again the set of equations presented in Figure \ref{fig:short_expl} and Example \ref{ex:short_expl} and suppose that the equations $(c_1,d_1),(d_1,d_2),(d_2,b)$ are inserted into the congruence structure before any other equation.
After adding these three equations, the proof forest contains of a single proof tree and is displayed in Figure \ref{fig:proof_forest_1}, where the labels are omitted.
Suppose that next following equations are inserted: $(a,f(c_1,e)),(f(c_4,e),c_1),(c_1,c_2),(c_2,c_3)$.
The resulting proof forest contains two proof trees and is shown in Figure \ref{fig:proof_forest_2}.
Finally the equation $(c_3,c_4)$ is added and the equality $f(c_1,e) \thickapprox f(c_4,e)$ is deduced.
At this point, the explanation for $c_1 \thickapprox c_4$ in the proof forest is the path $\langle c_1,c_2,c_3,c_4 \rangle$, which is the combined path from $c_1$ and $c_4$ to their nearest common ancestor, which is $c_2$.
The resulting proof forest is shown in Figure \ref{fig:proof_forest_3}, where the explanation for the edge $(f(c_1,e),f(c_4,e))$ is highlighted in a dotted rectangle.
The explanation for $a \thickapprox b$ in this graph is the path $\langle b,d_2,d_1,c_1,f(c_4,e),f(c_1,e),a\rangle$ and since the edge $(f(c_1,e),f(c_4,e))$ uses all other equations as explanation, the final explanation includes all eight equations.
In example \ref{ex:short_expl} we have shown that this is not necessary.

\begin{figure}[!h]
\input{chapters/congruence/figures/proof_forest_1}
\caption{Proof Forest including first three equations}
\label{fig:proof_forest_1}
\end{figure}

\begin{figure}[!h]
\input{chapters/congruence/figures/proof_forest_2}
\caption{Proof Forest before deducing}
\label{fig:proof_forest_2}
\end{figure}

\begin{figure}[!h]
\input{chapters/congruence/figures/proof_forest_3}
\caption{Final Proof Forest}
\label{fig:proof_forest_3}
\end{figure}

\end{example}

%See how BarceLogic ppl prove stuff,
%-) tree is still tree after inserting
%-) path to NCA forms explanation


\FloatBarrier